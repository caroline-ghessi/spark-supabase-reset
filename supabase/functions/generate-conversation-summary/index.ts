import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const supabase = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
)

const openAIApiKey = Deno.env.get('OPENAI_API_KEY')

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

console.log('üöÄ Generate Conversation Summary Function iniciada!')

serve(async (req) => {
  const requestId = crypto.randomUUID().substring(0, 8)
  console.log(`üîÑ [${requestId}] ${req.method} ${req.url}`)

  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  if (req.method !== 'POST') {
    return new Response('Method not allowed', { status: 405, headers: corsHeaders })
  }

  try {
    const { conversation_id } = await req.json()

    if (!conversation_id) {
      throw new Error('Par√¢metro obrigat√≥rio: conversation_id')
    }

    console.log(`üîÑ [${requestId}] Buscando conversa: ${conversation_id}`)

    // Buscar conversa
    const { data: conversation, error: convErr } = await supabase
      .from('conversations')
      .select('*')
      .eq('id', conversation_id)
      .single()

    if (convErr) {
      console.log(`‚ùå [${requestId}] Erro ao buscar conversa:`, convErr)
      throw new Error(`Conversa n√£o encontrada: ${convErr.message}`)
    }

    if (!conversation) {
      console.log(`‚ùå [${requestId}] Conversa n√£o encontrada: ${conversation_id}`)
      throw new Error('Conversa n√£o encontrada')
    }

    console.log(`‚úÖ [${requestId}] Conversa encontrada: ${conversation.client_name || conversation.client_phone}`)

    // Buscar hist√≥rico completo de mensagens da conversa
    const { data: messages, error: messagesErr } = await supabase
      .from('messages')
      .select('*')
      .eq('conversation_id', conversation_id)
      .order('created_at', { ascending: true })

    if (messagesErr) {
      console.log(`‚ùå [${requestId}] Erro ao buscar mensagens:`, messagesErr)
      const fallbackSummary = `**Cliente:** ${conversation.client_name || conversation.client_phone}
**Telefone:** ${conversation.client_phone}
**Temperatura:** ${conversation.lead_temperature === 'hot' ? 'Cliente Quente üî•' : conversation.lead_temperature === 'warm' ? 'Cliente Morno üü°' : 'Cliente Frio üîµ'}
**Valor Potencial:** R$ ${conversation.potential_value || 'N√£o informado'}
**Fonte:** ${conversation.source || 'WhatsApp'}

_Erro ao acessar hist√≥rico de mensagens. Resumo b√°sico dispon√≠vel._`
      
      return new Response(JSON.stringify({ 
        success: false,
        summary: fallbackSummary,
        error: 'messages_fetch_error',
        details: messagesErr.message
      }), { 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      })
    }

    console.log(`‚úÖ [${requestId}] ${messages?.length || 0} mensagens encontradas`)

    // Gerar resumo baseado na quantidade e tipo de mensagens
    console.log(`üìä [${requestId}] Analisando ${messages?.length || 0} mensagens para determinar tipo de resumo`)
    
    const messageCount = messages?.length || 0
    const hasClientMessages = messages?.some(m => m.sender_type === 'client') || false
    const hasBotMessages = messages?.some(m => m.sender_type === 'bot') || false
    
    console.log(`üîç [${requestId}] An√°lise de mensagens:`, {
      total: messageCount,
      hasClient: hasClientMessages,
      hasBot: hasBotMessages,
      conversationStatus: conversation.status
    })

    // Fun√ß√£o para gerar resumo b√°sico
    const generateBasicSummary = (reason: string, additionalInfo: string = '') => {
      const temperature = conversation.lead_temperature === 'hot' ? 'Cliente Quente üî•' : 
                         conversation.lead_temperature === 'warm' ? 'Cliente Morno üü°' : 'Cliente Frio üîµ'
      
      let summary = `**Cliente:** ${conversation.client_name || conversation.client_phone}
**Telefone:** ${conversation.client_phone}
**Temperatura:** ${temperature}
**Valor Potencial:** R$ ${conversation.potential_value || 'N√£o informado'}
**Fonte:** ${conversation.source || 'WhatsApp'}
**Status:** ${conversation.status}

${additionalInfo}`

      if (messageCount > 0) {
        const recentMessages = messages.slice(-3).map(msg => 
          `‚Ä¢ ${msg.sender_name}: ${msg.content || '[Arquivo/M√≠dia]'}`
        ).join('\n')
        
        summary += `\n\n**√öltimas mensagens:**\n${recentMessages}`
      }

      return summary
    }

    // 1. Conversa sem mensagens ou muito poucas
    if (messageCount === 0) {
      console.log(`‚ö†Ô∏è [${requestId}] Conversa sem mensagens`)
      const summary = generateBasicSummary('no_messages', '_Conversa criada mas sem mensagens trocadas._')
      
      return new Response(JSON.stringify({
        success: false,
        summary,
        error: 'no_messages',
        details: 'Conversa n√£o possui mensagens'
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      })
    }

    // 2. Conversas com poucas mensagens (1-2)
    if (messageCount <= 2) {
      console.log(`‚ö†Ô∏è [${requestId}] Conversa com poucas mensagens (${messageCount})`)
      const summary = generateBasicSummary('few_messages', `_Conversa inicial com apenas ${messageCount} mensagem(ns). Resumo detalhado n√£o dispon√≠vel._`)
      
      return new Response(JSON.stringify({
        success: false,
        summary,
        error: 'insufficient_messages',
        details: `Conversa possui apenas ${messageCount} mensagem(ns) - insuficiente para an√°lise detalhada`
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      })
    }

    // 3. Conversas com mensagens suficientes mas sem OpenAI configurado
    if (!openAIApiKey) {
      console.log(`‚ö†Ô∏è [${requestId}] OpenAI n√£o configurado - usando resumo b√°sico melhorado`)
      let summary = generateBasicSummary('openai_not_configured', '_IA n√£o configurada. Configure o OPENAI_API_KEY nos secrets do Supabase._')
      
      // Adicionar an√°lise b√°sica manual para conversas com mais mensagens
      if (messageCount >= 3) {
        const clientMessages = messages.filter(m => m.sender_type === 'client')
        const botMessages = messages.filter(m => m.sender_type === 'bot')
        
        summary += `\n\n**An√°lise B√°sica:**
‚Ä¢ Total de mensagens: ${messageCount}
‚Ä¢ Mensagens do cliente: ${clientMessages.length}
‚Ä¢ Respostas do bot: ${botMessages.length}
‚Ä¢ Dura√ß√£o da conversa: ${Math.round((new Date(messages[messages.length - 1].created_at).getTime() - new Date(messages[0].created_at).getTime()) / 60000)} minutos`
      }
      
      return new Response(JSON.stringify({
        success: false,
        summary,
        error: 'openai_not_configured',
        details: 'OPENAI_API_KEY n√£o est√° configurado'
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      })
    }

    // 4. Conversas com 3-4 mensagens - Resumo b√°sico com IA simples
    if (messageCount >= 3 && messageCount <= 4) {
      console.log(`üìù [${requestId}] Gerando resumo b√°sico com IA para ${messageCount} mensagens`)
      
      try {
        const conversationHistory = messages.map(msg => 
          `[${msg.sender_type}] ${msg.sender_name}: ${msg.content || '[Mensagem sem texto]'}`
        ).join('\n')

        const basicPrompt = `Analise esta conversa inicial e extraia as informa√ß√µes principais em um resumo conciso:

DADOS DO CLIENTE:
- Nome: ${conversation.client_name || 'N√£o informado'}
- Telefone: ${conversation.client_phone}
- Temperatura: ${conversation.lead_temperature}

CONVERSA:
${conversationHistory}

Gere um resumo focado em:
‚Ä¢ O que o cliente quer/precisa
‚Ä¢ Informa√ß√µes fornecidas pelo cliente
‚Ä¢ Pr√≥ximos passos sugeridos

Seja direto e objetivo (m√°ximo 200 palavras).`

        const aiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openAIApiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'gpt-4o-mini',
            messages: [
              { role: 'system', content: 'Voc√™ √© um assistente especializado em resumos comerciais concisos.' },
              { role: 'user', content: basicPrompt }
            ],
            max_tokens: 500,
            temperature: 0.3
          })
        })

        if (aiResponse.ok) {
          const aiData = await aiResponse.json()
          const basicSummary = `**Cliente:** ${conversation.client_name || conversation.client_phone}
**Telefone:** ${conversation.client_phone}
**Temperatura:** ${conversation.lead_temperature === 'hot' ? 'Cliente Quente üî•' : conversation.lead_temperature === 'warm' ? 'Cliente Morno üü°' : 'Cliente Frio üîµ'}

${aiData.choices[0].message.content}

_Resumo gerado automaticamente para conversa inicial com ${messageCount} mensagens._`
          
          console.log(`‚úÖ [${requestId}] Resumo b√°sico com IA gerado com sucesso`)
          return new Response(JSON.stringify({
            success: true,
            summary: basicSummary,
            conversation: {
              id: conversation.id,
              client_name: conversation.client_name,
              client_phone: conversation.client_phone,
              lead_temperature: conversation.lead_temperature,
              potential_value: conversation.potential_value
            }
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' }
          })
        } else {
          throw new Error(`OpenAI API Error: ${aiResponse.status}`)
        }
      } catch (error) {
        console.log(`‚ùå [${requestId}] Erro no resumo b√°sico IA:`, error)
        const fallbackSummary = generateBasicSummary('ai_basic_failed', `_Erro na gera√ß√£o do resumo b√°sico com IA. Mensagens: ${messageCount}_`)
        
        return new Response(JSON.stringify({
          success: false,
          summary: fallbackSummary,
          error: 'ai_basic_generation_failed',
          details: error.message
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        })
      }
    }

    // Gerar resumo com IA
    let aiSummary = ''
    try {
      console.log(`ü§ñ [${requestId}] Gerando resumo da conversa com IA...`)
      
      const conversationHistory = messages.map(msg => 
        `[${msg.sender_type}] ${msg.sender_name}: ${msg.content || '[Mensagem sem texto]'}`
      ).join('\n')

      console.log(`üìù [${requestId}] Hist√≥rico da conversa (${conversationHistory.length} chars):`, conversationHistory.substring(0, 200) + '...')

      const summaryPrompt = `Voc√™ √© um especialista em qualifica√ß√£o de leads e vendas. Analise esta conversa e extraia TODAS as informa√ß√µes comerciais relevantes para o vendedor assumir o atendimento de forma eficaz.

DADOS DO CLIENTE:
- Nome: ${conversation.client_name || 'N√£o informado'}
- Telefone: ${conversation.client_phone}
- Temperatura: ${conversation.lead_temperature}
- Valor Potencial: R$ ${conversation.potential_value || 'N√£o informado'}
- Fonte: ${conversation.source || 'WhatsApp'}

HIST√ìRICO COMPLETO DA CONVERSA:
${conversationHistory}

INSTRU√á√ÉO CR√çTICA: Analise cada mensagem em busca de informa√ß√µes comerciais espec√≠ficas. Gere um resumo DETALHADO e ESTRUTURADO com:

üéØ **PRODUTO/INTERESSE**:
- Qual produto espec√≠fico o cliente quer? (energia solar, inversor, pain√©is, etc.)
- Que capacidade/pot√™ncia mencionou? (kWp, kW, etc.)
- Qual a aplica√ß√£o? (residencial, comercial, industrial, rural)
- Mencionou marca ou especifica√ß√£o t√©cnica?

üìç **LOCALIZA√á√ÉO E CONTEXTO**:
- Qual cidade/regi√£o o cliente informou?
- Tipo de im√≥vel (casa, empresa, fazenda, etc.)
- Caracter√≠sticas do local mencionadas
- Dist√¢ncia da distribuidora/rede el√©trica

üí∞ **INVESTIMENTO E URG√äNCIA**:
- Cliente mencionou or√ßamento dispon√≠vel?
- Falou sobre prazo de pagamento preferido?
- Demonstrou urg√™ncia? Por qu√™?
- Mencionou financiamento ou forma de pagamento?

üîç **SITUA√á√ÉO ATUAL (SPIN)**:
- **Situa√ß√£o**: Como est√° hoje? (conta de luz alta, sem energia, etc.)
- **Problema**: Que dificuldades relatou?
- **Implica√ß√£o**: Como isso afeta o cliente?
- **Necessidade**: O que exatamente precisa resolver?

‚ö° **CONTEXTO T√âCNICO**:
- Consumo mencionado (kWh/m√™s, valor da conta)?
- Caracter√≠sticas da instala√ß√£o atual
- Limita√ß√µes ou desafios t√©cnicos mencionados
- Experi√™ncia pr√©via com energia solar

üéØ **OPORTUNIDADE DE VENDA**:
- Cliente est√° comparando propostas?
- Qual o principal motivador da compra?
- Sinais de interesse forte ou obje√ß√µes
- Pr√≥ximos passos ideais para fechamento

üìã **INFORMA√á√ïES CR√çTICAS**:
- Decisor da compra identificado?
- Prazo para decis√£o mencionado?
- Documenta√ß√£o necess√°ria discutida?
- Qualquer informa√ß√£o sens√≠vel ou importante

FORMATO: Use t√≥picos claros e diretos. Se alguma informa√ß√£o N√ÉO foi mencionada, escreva "N√£o informado" - mas procure TODAS as pistas no hist√≥rico.`

        const aiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openAIApiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'gpt-4o-mini',
            messages: [
              { role: 'system', content: 'Voc√™ √© um especialista em vendas e atendimento ao cliente.' },
              { role: 'user', content: summaryPrompt }
            ],
            max_tokens: 2000,
            temperature: 0.7
          })
        })

        if (aiResponse.ok) {
          const aiData = await aiResponse.json()
          aiSummary = aiData.choices[0].message.content
          console.log(`‚úÖ [${requestId}] Resumo IA gerado com sucesso (${aiSummary.length} chars)`)
        } else {
          const errorText = await aiResponse.text()
          console.log(`‚ùå [${requestId}] Falha na API OpenAI (${aiResponse.status}):`, errorText)
          throw new Error(`OpenAI API Error: ${aiResponse.status} - ${errorText}`)
        }
      } catch (aiError) {
        console.log(`‚ùå [${requestId}] Erro na gera√ß√£o do resumo IA:`, aiError)
        const fallbackSummary = `**Cliente:** ${conversation.client_name || conversation.client_phone}
**Telefone:** ${conversation.client_phone}
**Temperatura:** ${conversation.lead_temperature === 'hot' ? 'Cliente Quente üî•' : conversation.lead_temperature === 'warm' ? 'Cliente Morno üü°' : 'Cliente Frio üîµ'}
**Valor Potencial:** R$ ${conversation.potential_value || 'N√£o informado'}
**Fonte:** ${conversation.source || 'WhatsApp'}

_Erro na gera√ß√£o autom√°tica do resumo. Mensagens dispon√≠veis: ${messages.length}_

**Primeiras mensagens:**
${messages.slice(0, 3).map(msg => `‚Ä¢ ${msg.sender_name}: ${msg.content || '[Arquivo/M√≠dia]'}`).join('\n')}`
        
        return new Response(JSON.stringify({
          success: false,
          summary: fallbackSummary,
          error: 'ai_generation_failed',
          details: aiError.message
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        })
      }

    console.log(`‚úÖ [${requestId}] Resumo gerado com sucesso`)

    return new Response(JSON.stringify({
      success: true,
      summary: aiSummary,
      conversation: {
        id: conversation.id,
        client_name: conversation.client_name,
        client_phone: conversation.client_phone,
        lead_temperature: conversation.lead_temperature,
        potential_value: conversation.potential_value
      }
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    })

  } catch (error) {
    console.error(`‚ùå [${requestId}] Erro:`, error)
    return new Response(JSON.stringify({ 
      error: error.message,
      summary: '_Erro ao gerar resumo da conversa._'
    }), { 
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    })
  }
})